<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>MNIST · SimpleGrad.jl</title><meta name="title" content="MNIST · SimpleGrad.jl"/><meta property="og:title" content="MNIST · SimpleGrad.jl"/><meta property="twitter:title" content="MNIST · SimpleGrad.jl"/><meta name="description" content="Documentation for SimpleGrad.jl."/><meta property="og:description" content="Documentation for SimpleGrad.jl."/><meta property="twitter:description" content="Documentation for SimpleGrad.jl."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/custom.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">SimpleGrad.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Welcome</a></li><li><a class="tocitem" href="../../usage/">Usage</a></li><li><a class="tocitem" href="../../under_the_hood/">Under the Hood</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../linear_regression/">Linear Regression</a></li><li class="is-active"><a class="tocitem" href>MNIST</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Tutorials</a></li><li class="is-active"><a href>MNIST</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>MNIST</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/mikesaint-antoine/SimpleGrad.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/mikesaint-antoine/SimpleGrad.jl/blob/main/documentation_generator_edits/src/tutorials/mnist.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="MNIST-Example"><a class="docs-heading-anchor" href="#MNIST-Example">MNIST Example</a><a id="MNIST-Example-1"></a><a class="docs-heading-anchor-permalink" href="#MNIST-Example" title="Permalink"></a></h1><p>In this section, we&#39;ll use <em>Tensors</em> for a real neural net example – solving the <a href="https://en.wikipedia.org/wiki/MNIST_database">MNIST image classification problem.</a> The idea in this problem is to use a neural net to &quot;read&quot; images of hand-drawn numbers, from 0-9, and correctly identify which number each one is.</p><p><a href="https://www.kaggle.com/datasets/scolianni/mnistasjpg">You can download the MNIST images in JPG format here.</a> This should give you a folder called <code>archive</code>. Inside <code>archive</code>, there&#39;s a folder called <code>trainingSet</code>, and inside that folder there&#39;s another folder called <code>trainingSet</code>. If you follow this path and navigate to <code>archive/trainingSet/trainingSet/</code>, there are 10 folders numbered 0-9, each containing a collection of hand-drawn images of numbers corresponding to the folder they&#39;re in.</p><p>For example, here&#39;s the image at <code>archive/trainingSet/trainingSet/0/img_1.jpg</code>:</p><p><img src="../../assets/mnist_images/img_1_resized.jpg" alt="mnist_example"/></p><p>Here&#39;s the image at <code>archive/trainingSet/trainingSet/5/img_119.jpg</code>:</p><p><img src="../../assets/mnist_images/img_119_resized.jpg" alt="mnist_example"/></p><p>Here&#39;s the image at <code>archive/trainingSet/trainingSet/8/img_20.jpg</code>:</p><p><img src="../../assets/mnist_images/img_20_resized.jpg" alt="mnist_example"/></p><p>We can load this image into Julia with:</p><pre><code class="language-julia hljs">using Images

img_path = &quot;archive/trainingSet/trainingSet/8/img_20.jpg&quot;
img = load(img_path)</code></pre><p>Next, we&#39;ll convert the image to a matrix of numbers. Since the images are 28x28 pixels, the matrix representation will be 28x28 numbers, with each corresponding to a pixel. </p><pre><code class="language-julia hljs">img_mat = Float64.(img)

println(size(img_mat))
# output: (28,28)</code></pre><p>But for the neural network we&#39;re about to make, we actualy want a flattened 1-dimensional representation of the image, rather than a 2-dimensional matrix. So we&#39;ll flatten the image like this, to get a 1-dimensional array of length 28x28=784.</p><pre><code class="language-julia hljs">img_flattened = reshape(img_mat, :)

println(size(img_flattened))
# output: (784,)</code></pre><p>Ok, so that was an example for one image. Now we&#39;re going to read in all of the images, flatten them, and store them as rows in a matrix called <code>X</code>. So when we&#39;re done, we should have a matrix <code>X</code> with shape <code>(N,784)</code>, where <code>N</code> is the number of images we read in. We&#39;ll also store the label of each image (what number it is) in an array called <code>y</code>, so that each element of <code>y</code> tells us what number the corresponding row in <code>X</code> is.</p><pre><code class="language-julia hljs"># reading in images

base_path = &quot;archive/trainingSet/trainingSet/&quot;

X = [] # image pixel data. end result will be (N,784)
y = [] # digit label. end result will be (N,)


for digit in 0:9
    folder_path = joinpath(base_path, string(digit))
    for file in readdir(folder_path)
        img_path = joinpath(folder_path, file)
        img = load(img_path)
        img_mat = Float64.(img)
        img_flattened = reshape(img_mat, :)
        push!(X, img_flattened)
        push!(y, digit)  
        
    end

end


X = hcat(X...)&#39; # transposing to (N, 784)

println(size(X))
# output: (42000, 784)

println(size(y))
# output: (42000,)</code></pre><p>So far, so good! Looks like we successfully read in 42,000 images. Now we&#39;ll shuffle the image data and labels, but making sure to keep them in the same order as each other, with elements in <code>y</code> still corresponding to rows in <code>X</code>. Here&#39;s how we can do that:</p><pre><code class="language-julia hljs">using Random
Random.seed!(1234)
# seeding the random number generator for reproducibility

n = size(X,1)

perm = shuffle(1:n)
X = X[perm, :]
y = y[perm]</code></pre><p>Next we&#39;ll split up the data into training and testing sets. We&#39;ll use 80% of it for training, and set aside 20% for testing.</p><pre><code class="language-julia hljs">train_size = Int(0.8 * size(X,1))

X_train = X[1:train_size, :]
y_train = y[1:train_size]

X_test = X[train_size+1:end, :]
y_test = y[train_size+1:end]

println(size(X_train))
# output: (33600, 784)
println(size(y_train))
# output: (33600,)

println(size(X_test))
# output: (8400, 784)
println(size(y_test))
# output: (8400,)</code></pre><p>Now it&#39;s time to actually start defining our neural network model. We want our model to take in 784 inputs per sample (the size of the flattened 28x28 pixel images). Our inner layer will have 128 neurons, and our final layer will have 10 neurons (corresponding to the 10 possible digits that the image could be). So, we&#39;ll need to make sure we shape our <em>Tensors</em> accordingly. Here&#39;s the code:</p><pre><code class="language-julia hljs">using SimpleGrad

# initializing parameters

# layer 1
weights1 = Tensor(0.01 * rand(784, 128)) # taking in 784 input features, has 128 neurons in the layer
biases1 = Tensor(zeros(128))

# layer 2
weights2 = Tensor(0.01 * rand(128, 10)) # taking 128 inputs (from 128 neurons in the first layer), has 10 neurons in the layer
biases2 = Tensor(zeros(10))</code></pre><p>Next, some hyperparameters: the batch size, number of classes, number of epochs, and learning rate.</p><pre><code class="language-julia hljs"># hyperparameters
batch_size = 100
num_classes = 10
epochs = 3
lr = 0.1</code></pre><p>Now, we train the model:</p><pre><code class="language-julia hljs">global run = 1
for epoch in 1:epochs
    for i in 1:batch_size:size(X_train,1)
    
    
        # size of input matrix = (batch_size, 784)
        batch_X = Tensor(X_train[i:i+batch_size-1, :])
        batch_y = y_train[i:i+batch_size-1]
        
        
        
        ## convert batch_y to one-hot
        batch_y_one_hot = zeros(batch_size,num_classes)
        for batch_ind in 1:batch_size
            batch_y_one_hot[batch_ind,Int.(batch_y)[batch_ind]+1] = 1
        end
        
        
        ## zero grads
        weights1.grad .= 0
        weights2.grad .= 0
        biases1.grad .= 0
        biases2.grad .= 0
        
        
        # layer 1
        layer1_out = relu(batch_X * weights1 + biases1);
        
        # layer 2
        layer2_out = layer1_out * weights2 + biases2
        
        
        loss = softmax_crossentropy(layer2_out,batch_y_one_hot)
            
        
        backward(loss)
        
        
        # updating parameter values based on gradient
        weights1.data = weights1.data - weights1.grad .* lr
        biases1.data = biases1.data - biases1.grad .* lr
        weights2.data = weights2.data - weights2.grad .* lr
        biases2.data = biases2.data - biases2.grad .* lr;


        if run % 10 == 0
            println(&quot;Epoch: run, loss: $(round(loss.data[1], digits=3))&quot;)
        end
        
        global run += 1
    
    end
end

# output:
# epoch: 1, run: 50, loss: 2.136
# epoch: 1, run: 100, loss: 1.239
# epoch: 1, run: 150, loss: 0.77
# epoch: 1, run: 200, loss: 0.578
# epoch: 1, run: 250, loss: 0.493
# epoch: 1, run: 300, loss: 0.457
# epoch: 2, run: 50, loss: 0.421
# epoch: 2, run: 100, loss: 0.372
# epoch: 2, run: 150, loss: 0.302
# epoch: 2, run: 200, loss: 0.299
# epoch: 2, run: 250, loss: 0.341
# epoch: 2, run: 300, loss: 0.341</code></pre><p>Now, let&#39;s check out performance on the testing set:</p><pre><code class="language-julia hljs">global correct = 0
global total = 0
for i in 1:length(y_test)
    X_in = X_test[i:i,:] ## need to keep this (1,784), not (784,)
    X_in = Tensor(X_in)
    y_true = y_test[i]

    layer1_out = relu(X_in * weights1 + biases1)
    layer2_out = layer1_out * weights2 + biases2


    pred_argmax = argmax(layer2_out.data, dims=2)[1][2]

    if pred_argmax-1 == y_true # -1 because digits start at 0
        global correct +=1
    end
    global total += 1

end

println(correct/total)
# output: 0.9036904761904762</code></pre><p>90.36% accuracy on the testing set. Not bad!</p><p>Lastly, just for fun, we can put the trained model inside of a user-friendly function, so the user can point the model towards an image file path, and then the function will automatically read in the image, pass it through the model, and generate a guess about what number it is. Here&#39;s the function:</p><pre><code class="language-julia hljs"># user-friendly function

function guess_digit(img_path::String)
    
    # load image and conver to Tensor
    img = load(img_path)
    img_mat = Float64.(img)
    img_flattened = reshape(img_mat, :)
    img_tensor = Tensor(img_flattened)
    
    layer1_out = relu(img_tensor * weights1 + biases1)
    layer2_out = layer1_out * weights2 + biases2
    pred_argmax = argmax(layer2_out.data, dims=2)[1][2]
    prediction = pred_argmax-1 # because digits start at 0
    
    println(&quot;Guess: $prediction&quot;)
    
    
end</code></pre><p>Then we can try it out with an image from <code>archive/testSet/testSet</code>, which the model hasn&#39;t seen yet. </p><pre><code class="language-julia hljs">img_path = &quot;archive/testSet/testSet/img_3.jpg&quot;

guess_digit(img_path)
# output: &quot;Guess: 9&quot; </code></pre><p>The model guesses 9, and if we check that image we can confirm that it is indeed a 9!</p><p><img src="../../assets/mnist_images/img_3_resized.jpg" alt="mnist_example"/></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../linear_regression/">« Linear Regression</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.8.0 on <span class="colophon-date" title="Saturday 25 January 2025 17:10">Saturday 25 January 2025</span>. Using Julia version 1.11.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
